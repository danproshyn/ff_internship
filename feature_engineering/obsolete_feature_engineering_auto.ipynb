{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2feee7ca31e2aa12",
   "metadata": {},
   "source": [
    "# Automated Feature Engineering (featuretools)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import warnings\n",
    "\n",
    "import featuretools as ft\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.imputation import AddMissingIndicator, ArbitraryNumberImputer, MeanMedianImputer\n",
    "# from dask.distributed import LocalCluster\n",
    "from featuretools.primitives import TimeSinceFirst, TimeSinceLast\n",
    "from tsfresh import extract_features, extract_relevant_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from woodwork.logical_types import Boolean, BooleanNullable, Categorical, Unknown\n",
    "\n",
    "from utils import add_calendar_values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "918ccc38ce8a3fe6",
   "metadata": {},
   "source": [
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "warnings.simplefilter(action='ignore', category=FutureWarning)",
   "id": "411f3e5b9850db93"
  },
  {
   "cell_type": "markdown",
   "id": "9cc1e306289de8f",
   "metadata": {},
   "source": [
    "## Create EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "id": "88d84825e7a3b29c",
   "metadata": {},
   "source": [
    "es = ft.EntitySet(id='client_data')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4db282296011dd6a",
   "metadata": {},
   "source": [
    "\"\"\"Clients\"\"\"\n",
    "\n",
    "from utils import read_clients\n",
    "\n",
    "# CLIENTS_PATH = '../data/initial/CLIENTS.csv'\n",
    "CLIENTS_PATH = '../data/samples/CLIENTS_SAMPLE.csv'\n",
    "\n",
    "clients_df = read_clients(CLIENTS_PATH, encode_bool=False)\n",
    "clients_df = clients_df.astype({'client_id': str})\n",
    "display(clients_df.info())\n",
    "\n",
    "es.add_dataframe(\n",
    "    clients_df,\n",
    "    dataframe_name='clients',\n",
    "    index='client_id',\n",
    "    time_index='communication_month',\n",
    "    # make_index=True,\n",
    "    logical_types={\n",
    "        'client_id': Unknown,\n",
    "        'target': Boolean,\n",
    "        'is_train': Boolean,\n",
    "    }\n",
    ")\n",
    "display(es['clients'].ww.schema)\n",
    "display(es)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2893f7b499d2a8c7",
   "metadata": {},
   "source": [
    "\"\"\"Transactions\"\"\"\n",
    "\n",
    "from utils import read_transactions\n",
    "\n",
    "# TRANSACTIONS_PATH = '../data/initial/TRANSACTIONS.csv'\n",
    "TRANSACTIONS_PATH = '../data/samples/TRANSACTIONS_SAMPLE.csv'\n",
    "\n",
    "transactions_df = read_transactions(TRANSACTIONS_PATH, encode_bool=False, encode_category=False)\n",
    "transactions_df = transactions_df.astype({'client_id': str})\n",
    "# transactions_df['tran_date_str'] = transactions_df['tran_date'].dt.date.astype(str)  # used later for feature generation\n",
    "transactions_df = add_calendar_values(transactions_df, 'tran_date', prefix='tran_date_')\n",
    "display(transactions_df.info())\n",
    "\n",
    "es.add_dataframe(\n",
    "    transactions_df,\n",
    "    dataframe_name='transactions',\n",
    "    index='transaction_id',\n",
    "    time_index='tran_date',\n",
    "    make_index=True,\n",
    "    logical_types={\n",
    "        'client_id': Unknown,\n",
    "        'cat_c2': Categorical,\n",
    "        'cat_c3': Categorical,\n",
    "        'cat_c4': Categorical,\n",
    "        # 'tran_date_str': Categorical,\n",
    "        'fl_c6': Boolean,\n",
    "        'fl_c7': Boolean,\n",
    "        'fl_c8': Boolean,\n",
    "        'fl_c9': Boolean,\n",
    "        'fl_c10': Boolean,\n",
    "        'fl_c11': Boolean,\n",
    "        'fl_c12': Boolean,\n",
    "        'fl_c13': Boolean,\n",
    "        'fl_c14': Boolean,\n",
    "        'fl_c15': Boolean,\n",
    "    }\n",
    ")\n",
    "display(es['transactions'].ww.schema)\n",
    "\n",
    "es.add_relationship('clients', 'client_id', 'transactions', 'client_id')\n",
    "display(es)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27e8b4cc305bb6ea",
   "metadata": {},
   "source": [
    "\"\"\"App activity\"\"\"\n",
    "\n",
    "from utils import preprocess_app_activity_data, read_app_activity\n",
    "\n",
    "# ACTIVITY_PATH = '../data/initial/APP_ACTIVITY.csv'\n",
    "ACTIVITY_PATH = '../data/samples/APP_ACTIVITY_SAMPLE.csv'\n",
    "\n",
    "activities_df = read_app_activity(ACTIVITY_PATH, encode_bool=False, encode_category=False)\n",
    "activities_df = activities_df.astype({'client_id': str})\n",
    "activities_df = preprocess_app_activity_data(activities_df)\n",
    "# activities_df['activity_date_str'] = activities_df['activity_date'].dt.date.astype(str)  # used later for feature generation\n",
    "activities_df = add_calendar_values(activities_df, 'activity_date', prefix='activity_date_')\n",
    "display(activities_df.info())\n",
    "\n",
    "es.add_dataframe(\n",
    "    activities_df,\n",
    "    dataframe_name='activities',\n",
    "    index='activity_id',\n",
    "    time_index='activity_date',\n",
    "    make_index=True,\n",
    "    logical_types={\n",
    "        'client_id': Unknown,\n",
    "        'cat_c3': Categorical,\n",
    "        'cat_c4': Categorical,\n",
    "        'cat_c5': Categorical,\n",
    "        'cat_c6': Categorical,\n",
    "        'cat_c9': Categorical,\n",
    "        # 'activity_date_str': Categorical,\n",
    "        'cat_c8': BooleanNullable,\n",
    "        'cat_c10': BooleanNullable,\n",
    "    }\n",
    ")\n",
    "display(es['activities'].ww.schema)\n",
    "\n",
    "es.add_relationship('clients', 'client_id', 'activities', 'client_id')\n",
    "display(es)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "32069500986d1ed1",
   "metadata": {},
   "source": [
    "\"\"\"Communications\"\"\"\n",
    "\n",
    "from utils import read_communications\n",
    "\n",
    "# COMMS_PATH = '../data/initial/COMMUNICATIONS.csv'\n",
    "COMMS_PATH = '../data/samples/COMMUNICATIONS_SAMPLE.csv'\n",
    "\n",
    "comms_df = read_communications(COMMS_PATH, encode_category=False)\n",
    "comms_df = comms_df.astype({'client_id': str})\n",
    "# comms_df = preprocess_comm_data(comms)\n",
    "# comms_df = encode_comm_categories(comms)\n",
    "# comms_df['contact_date_str'] = comms_df['contact_date'].dt.date.astype(str)  # used later for feature generation\n",
    "comms_df = add_calendar_values(comms_df, 'contact_date', prefix='contact_date_')\n",
    "display(comms_df.info(show_counts=True))\n",
    "\n",
    "es.add_dataframe(\n",
    "    comms_df,\n",
    "    dataframe_name='comms',\n",
    "    index='comm_id',\n",
    "    time_index='contact_date',\n",
    "    make_index=True,\n",
    "    logical_types={\n",
    "        'client_id': Unknown,\n",
    "        'cat_c2': Categorical,\n",
    "        'cat_c3': Categorical,\n",
    "        'cat_c4': Categorical,\n",
    "        'cat_c5': Categorical,\n",
    "        # 'contact_date_str': Categorical,\n",
    "    }\n",
    ")\n",
    "display(es['comms'].ww.schema)\n",
    "\n",
    "es.add_relationship('clients', 'client_id', 'comms', 'client_id')\n",
    "display(es)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6620c2ee8aac331f",
   "metadata": {},
   "source": [
    "es.add_last_time_indexes()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e058501997630517",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "id": "f60b6b9528c9217e",
   "metadata": {},
   "source": [
    "MIN_DATE_STR = '2024-12-01 00:00:00'\n",
    "MAX_DATE_STR = '2025-09-01 00:00:00'\n",
    "\n",
    "agg_primitives = [\n",
    "    'count',\n",
    "    'first', 'last', TimeSinceFirst(unit='days'), TimeSinceLast(unit='days'),  # for date\n",
    "    'mean', 'std', 'skew', 'kurtosis', 'min', 'max', 'sum',   # for numeric\n",
    "    'num_unique', 'mode', 'entropy',  # for categorical\n",
    "    'percent_true',  # for boolean\n",
    "]\n",
    "\n",
    "primitive_options = {}\n",
    "for agg in agg_primitives:\n",
    "    primitive_options[agg]= {'include_columns': {}}\n",
    "    for df_name in ('transactions', 'activities', 'comms'):\n",
    "         if agg not in ('count',) and isinstance(agg, str):\n",
    "             primitive_options[agg]['include_columns'][df_name] = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea36db377fa153b3",
   "metadata": {},
   "source": [
    "\"\"\"Transactions\"\"\"\n",
    "\n",
    "df_name = 'transactions'\n",
    "\n",
    "# Date\n",
    "for prim in ['first', 'last']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += ['tran_date']\n",
    "primitive_options['mean']['include_columns'][df_name] += [\n",
    "    'tran_date_day_of_week_sin', 'tran_date_day_of_week_cos',\n",
    "    'tran_date_day_of_month_sin', 'tran_date_day_of_month_cos',\n",
    "]\n",
    "\n",
    "# Numeric\n",
    "num_cols = ['float_c16', 'float_c17', 'float_c18', 'int_c19', 'float_c20', 'float_c21']\n",
    "for prim in ['mean', 'std', 'skew', 'kurtosis', 'min', 'max', 'sum']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += num_cols\n",
    "    # primitive_options[prim] = {'include_columns': {df_name: num_cols}}\n",
    "\n",
    "# Categorical\n",
    "cat_cols = list(es[df_name].ww.select(Categorical).columns)\n",
    "for prim in ['num_unique', 'mode', 'entropy']:\n",
    "    # primitive_options['mode'] = {'include_columns': {df_name: cat_cols}}\n",
    "    primitive_options[prim]['include_columns'][df_name] += cat_cols\n",
    "# for prim in ('mode', 'entropy'):\n",
    "#     # Delete redundant primitive\n",
    "#     primitive_options[prim]['include_columns'][df_name].remove('tran_date_str')\n",
    "\n",
    "# Boolean\n",
    "bool_cols = list(es[df_name].ww.select([Boolean, BooleanNullable]).columns)\n",
    "# primitive_options['percent_true'] = {'include_columns': {df_name: bool_cols}}\n",
    "primitive_options['percent_true']['include_columns'][df_name] += bool_cols\n",
    "\n",
    "\n",
    "# Interesting values\n",
    "interesting_values = {\n",
    "    'cat_c2': [4, 14, 15],\n",
    "    'cat_c3': [209, 303, 305, 314],\n",
    "    'int_c19': [-1, 1],\n",
    "    'fl_c12': [True, False],\n",
    "    'fl_c13': [True, False],\n",
    "    'fl_c14': [True, False],\n",
    "    'tran_date_is_weekend': [True, False],\n",
    "}\n",
    "es.add_interesting_values(dataframe_name=df_name, values=interesting_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "163b6e796650113f",
   "metadata": {},
   "source": [
    "\"\"\"Activities\"\"\"\n",
    "\n",
    "df_name = 'activities'\n",
    "\n",
    "# Date\n",
    "for prim in ['first', 'last']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += ['activity_date']\n",
    "primitive_options['mean']['include_columns'][df_name] += [\n",
    "    'activity_date_day_of_week_sin', 'activity_date_day_of_week_cos',\n",
    "    'activity_date_day_of_month_sin', 'activity_date_day_of_month_cos',\n",
    "]\n",
    "\n",
    "# Numeric\n",
    "num_cols = ['float_c11', 'float_c12', 'float_c13', 'float_c14', 'float_c15', 'float_c16', 'float_c17']\n",
    "for prim in ['mean', 'std', 'skew', 'kurtosis', 'min', 'max', 'sum']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += num_cols\n",
    "\n",
    "# Categorical\n",
    "cat_cols = list(es[df_name].ww.select(Categorical).columns)\n",
    "for prim in ['num_unique', 'mode', 'entropy']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += cat_cols\n",
    "# for prim in ('mode', 'entropy'):\n",
    "#     # Delete redundant primitive\n",
    "#     primitive_options[prim]['include_columns'][df_name].remove('activity_date_str')\n",
    "\n",
    "# Boolean\n",
    "bool_cols = list(es[df_name].ww.select([Boolean, BooleanNullable]).columns)\n",
    "primitive_options['percent_true']['include_columns'][df_name] += bool_cols\n",
    "\n",
    "\n",
    "# Interesting values\n",
    "interesting_values = {\n",
    "    'cat_c4': [1, 2],\n",
    "    'cat_c6': [1, 2, 3],\n",
    "    'cat_c9': [1, 2],\n",
    "    'cat_c8': [True, False],\n",
    "    'cat_c10': [True, False],\n",
    "    'activity_date_is_weekend': [True, False],\n",
    "}\n",
    "es.add_interesting_values(dataframe_name=df_name, values=interesting_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0fea3b275ee9ebb",
   "metadata": {},
   "source": [
    "\"\"\"Communications\"\"\"\n",
    "\n",
    "df_name = 'comms'\n",
    "\n",
    "# Date\n",
    "for prim in ['first', 'last']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += ['contact_date']\n",
    "primitive_options['mean']['include_columns'][df_name] += [\n",
    "    'contact_date_day_of_week_sin', 'contact_date_day_of_week_cos',\n",
    "    'contact_date_day_of_month_sin', 'contact_date_day_of_month_cos',\n",
    "]\n",
    "\n",
    "# Categorical\n",
    "cat_cols = list(es[df_name].ww.select(Categorical).columns)\n",
    "for prim in ['num_unique', 'mode', 'entropy']:\n",
    "    primitive_options[prim]['include_columns'][df_name] += cat_cols\n",
    "# for prim in ('mode', 'entropy'):\n",
    "#     # Delete redundant primitive\n",
    "#     primitive_options[prim]['include_columns'][df_name].remove('contact_date_str')\n",
    "\n",
    "\n",
    "# Boolean\n",
    "bool_cols = list(es[df_name].ww.select([Boolean, BooleanNullable]).columns)\n",
    "primitive_options['percent_true']['include_columns'][df_name] += bool_cols\n",
    "\n",
    "# Interesting values\n",
    "interesting_values = {\n",
    "    'cat_c2': ['S3564', 'S3565', 'S3677', 'S3769'],\n",
    "    'cat_c3': [3, 4, 7],\n",
    "    'cat_c4': [1, 2],\n",
    "    'cat_c5': ['4', '7'],\n",
    "    'contact_date_is_weekend': [True, False],\n",
    "}\n",
    "es.add_interesting_values(dataframe_name=df_name, values=interesting_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4cc9c09c449e7fb",
   "metadata": {},
   "source": [
    "# Cut-off time dataframe\n",
    "cutoff_df = clients_df[['client_id', 'communication_month']].copy()\n",
    "cutoff_df.rename(columns={'communication_month': 'time'}, inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbcf3ff60de2f901",
   "metadata": {},
   "source": [
    "# cluster = LocalCluster()\n",
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='clients',\n",
    "    # ignore_dataframes=['transactions', 'comms'],\n",
    "    # cutoff_time=transactions_df['tran_date'].max(),\n",
    "    cutoff_time=cutoff_df,\n",
    "    agg_primitives=agg_primitives,\n",
    "    trans_primitives=['day', 'month', 'weekday', 'is_weekend'],\n",
    "    where_primitives=['mean', 'sum', 'count'],\n",
    "    primitive_options=primitive_options,\n",
    "    max_depth=1,\n",
    "    verbose=True,\n",
    "    features_only=False,\n",
    "    n_jobs=1,\n",
    "    chunk_size=es.dataframe_dict['clients'].shape[0],\n",
    "    # dask_kwargs={'cluster': cluster.scheduler.address},\n",
    "    return_types='all',\n",
    ")\n",
    "feature_matrix_enc, features_enc = ft.encode_features(\n",
    "    feature_matrix,\n",
    "    feature_defs,\n",
    "    top_n={\n",
    "        # Transactions\n",
    "        'MODE(transactions.cat_c2)': 10,\n",
    "        'MODE(transactions.cat_c3)': 10,\n",
    "        'MODE(transactions.cat_c4)': 5,\n",
    "\n",
    "        # Activities\n",
    "        'MODE(activities.cat_c3)': 3,\n",
    "        'MODE(activities.cat_c4)': 2,\n",
    "        'MODE(activities.cat_c5)': 1,\n",
    "        'MODE(activities.cat_c6)': 7,\n",
    "        'MODE(activities.cat_c9)': 2,\n",
    "\n",
    "        # Communications\n",
    "        'MODE(comms.cat_c2)': 10,\n",
    "        'MODE(comms.cat_c3)': 3,\n",
    "        'MODE(comms.cat_c4)': 3,\n",
    "        'MODE(comms.cat_c5)': 3,\n",
    "    },\n",
    "    to_encode=[\n",
    "        'MODE(transactions.cat_c2)', 'MODE(transactions.cat_c3)', 'MODE(transactions.cat_c4)',  # transactions\n",
    "        'MODE(activities.cat_c3)', 'MODE(activities.cat_c4)', 'MODE(activities.cat_c5)', 'MODE(activities.cat_c6)', 'MODE(activities.cat_c9)',  # activities\n",
    "        'MODE(comms.cat_c2)', 'MODE(comms.cat_c3)', 'MODE(comms.cat_c4)', 'MODE(comms.cat_c5)',  # communications\n",
    "    ],\n",
    ")\n",
    "ft.save_features(features_enc, '../data/features/feature_definitions_v5_single.json')\n",
    "feature_matrix_enc.to_csv('../data/features/features_auto_v5_single_raw.csv', index=False)\n",
    "\n",
    "display(features_enc)\n",
    "display(feature_matrix_enc.head())\n",
    "display(feature_matrix_enc.info(verbose=True, show_counts=True))\n",
    "display(feature_matrix_enc.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6eae6427abf326ed",
   "metadata": {},
   "source": [
    "## Ratios between last 45/90 days periods"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3af9c8c7692ea70",
   "metadata": {},
   "source": [
    "fm_45d, _ = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='clients',\n",
    "    cutoff_time=cutoff_df,\n",
    "    training_window='45 days',\n",
    "    agg_primitives=['count', 'sum', 'mean', 'std', 'percent_true'],\n",
    "    trans_primitives=[],\n",
    "    where_primitives=['count'],\n",
    "    primitive_options=primitive_options,\n",
    "    max_depth=1,\n",
    "    verbose=True,\n",
    "    features_only=False,\n",
    "    n_jobs=1,\n",
    "    chunk_size=es.dataframe_dict['clients'].shape[0],\n",
    "    return_types='all',\n",
    ")\n",
    "fm_90d, _ = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='clients',\n",
    "    cutoff_time=cutoff_df,\n",
    "    training_window='90 days',\n",
    "    agg_primitives=['count', 'sum', 'mean', 'std', 'percent_true'],\n",
    "    trans_primitives=[],\n",
    "    where_primitives=['count'],\n",
    "    primitive_options=primitive_options,\n",
    "    max_depth=1,\n",
    "    verbose=True,\n",
    "    features_only=False,\n",
    "    n_jobs=1,\n",
    "    chunk_size=es.dataframe_dict['clients'].shape[0],\n",
    "    return_types='all',\n",
    ")\n",
    "\n",
    "# Rename to make columns unique\n",
    "fm_45d = fm_45d.add_prefix('D45_')\n",
    "fm_90d = fm_90d.add_prefix('D90_')\n",
    "\n",
    "trend_features = pd.DataFrame(index=fm_45d.index)\n",
    "for col_45, col_90 in zip(fm_45d.columns, fm_90d.columns):\n",
    "    col = col_45.replace('D45_', '')\n",
    "    if col in ['client_id', 'target', 'is_train']:\n",
    "        continue\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(fm_45d[col_45]):\n",
    "        trend_features[f\"TREND_45_90_{col}\"] = fm_45d[col_45] / fm_90d[col_90].replace(0, np.nan)\n",
    "\n",
    "trend_features.fillna(0, inplace=True)\n",
    "\n",
    "display(trend_features.head())\n",
    "display(trend_features.info(verbose=True, show_counts=True))\n",
    "\n",
    "feature_matrix_enc = feature_matrix_enc.merge(trend_features, on='client_id', how='left')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Other features",
   "id": "27d83ad365c94dd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extra unique features",
   "id": "864872599ff8ee61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transactions_df['tran_date_str'] = transactions_df['tran_date'].dt.date.astype('category')\n",
    "tx_dates_unique = transactions_df.groupby('client_id').agg(tran_date_str_nunique=('tran_date_str', 'nunique')).reset_index(names='client_id')\n",
    "\n",
    "activities_df['activity_date_str'] = activities_df['activity_date'].dt.date.astype('category')\n",
    "act_dates_unique = activities_df.groupby('client_id').agg(activity_date_str_nunique=('activity_date_str', 'nunique')).reset_index(names='client_id')\n",
    "act_devices_unique = activities_df.groupby('client_id').agg(device_id_nunique=('device_id', 'nunique')).reset_index(names='client_id')\n",
    "\n",
    "comms_df['contact_date_str'] = comms_df['contact_date'].dt.date.astype('category')\n",
    "comms_dates_unique = comms_df.groupby('client_id').agg(contact_date_str_nunique=('contact_date_str', 'nunique')).reset_index(names='client_id')\n",
    "\n",
    "feature_matrix_enc = feature_matrix_enc.merge(comms_dates_unique, on='client_id', how='left')\n",
    "feature_matrix_enc = feature_matrix_enc.merge(act_dates_unique, on='client_id', how='left')\n",
    "feature_matrix_enc = feature_matrix_enc.merge(act_devices_unique, on='client_id', how='left')\n",
    "feature_matrix_enc = feature_matrix_enc.merge(tx_dates_unique, on='client_id', how='left')"
   ],
   "id": "d31bf19efa3260c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cross-table interaction features",
   "id": "7e45ce20db34d244"
  },
  {
   "cell_type": "code",
   "id": "16ca07fd803c0277",
   "metadata": {},
   "source": [
    "feature_matrix_enc['INTERACTION_activity_per_trans'] = feature_matrix_enc['COUNT(activities)'] / feature_matrix_enc['COUNT(transactions)'].replace(0, 1)\n",
    "feature_matrix_enc['INTERACTION_contact_per_trans'] = feature_matrix_enc['COUNT(comms)'] / feature_matrix_enc['COUNT(transactions)'].replace(0, 1)\n",
    "feature_matrix_enc['INTERACTION_contact_per_activity'] = feature_matrix_enc['COUNT(comms)'] / feature_matrix_enc['COUNT(activities)'].replace(0, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3623a284a00e4188",
   "metadata": {},
   "source": "Financial balance"
  },
  {
   "cell_type": "code",
   "id": "84fa2fb5180bcc76",
   "metadata": {},
   "source": [
    "pos_sum = feature_matrix_enc['SUM(transactions.float_c18 WHERE int_c19 = 1)']\n",
    "neg_sum = feature_matrix_enc['SUM(transactions.float_c18 WHERE int_c19 = -1)']\n",
    "feature_matrix_enc['BALANCE_net_flow'] = pos_sum - neg_sum\n",
    "feature_matrix_enc['BALANCE_savings_potential'] = pos_sum / neg_sum"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b3837e5c7c6c2f12",
   "metadata": {},
   "source": [
    "## Add more time-series features"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a3b1f460f44575e",
   "metadata": {},
   "source": [
    "def prep_time_gaps(df, date_col, prefix):\n",
    "    df = df.sort_values(by=['client_id', date_col])\n",
    "\n",
    "    gap_col_name = f'{prefix}_gap_days'\n",
    "    df[gap_col_name] = df.groupby('client_id')[date_col].diff().dt.total_seconds() / (3600 * 24)\n",
    "    df[gap_col_name] = df[gap_col_name].fillna(0)\n",
    "\n",
    "    return df[['client_id', date_col, gap_col_name]]\n",
    "\n",
    "df_transactions_ts = prep_time_gaps(transactions_df, 'tran_date', 'tran_date')\n",
    "df_transactions_ts['float_c18_diff'] = transactions_df.groupby('client_id')['float_c18'].diff().fillna(0)  # difference between transactions amount\n",
    "df_activities_ts = prep_time_gaps(activities_df, 'activity_date', 'activity_date')\n",
    "df_comms_ts  = prep_time_gaps(comms_df, 'contact_date', 'contact_date')\n",
    "\n",
    "display(df_transactions_ts.head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eca70e3a37a3f1d4",
   "metadata": {},
   "source": [
    "datasets = {\n",
    "    'transactions': (df_transactions_ts, 'tran_date', ['tran_date_gap_days', 'float_c18_diff']),\n",
    "    'activities': (df_activities_ts, 'activity_date', ['activity_date_gap_days']),\n",
    "    'communications': (df_comms_ts, 'contact_date', ['contact_date_gap_days'])\n",
    "}\n",
    "all_features = []\n",
    "for name, (df, date_col, val_cols) in datasets.items():\n",
    "    print(f'Processing {name}...')\n",
    "\n",
    "    for val_col in val_cols:\n",
    "        fc_parameters = {\n",
    "            'median': None,\n",
    "            'mean': None,\n",
    "            'maximum': None,\n",
    "            'minimum': None,\n",
    "            'standard_deviation': None,\n",
    "            'skewness': None,\n",
    "            'kurtosis': None,\n",
    "            'quantile': [\n",
    "                {'q': 0.1},\n",
    "                {'q': 0.25},\n",
    "                {'q': 0.75},\n",
    "                {'q': 0.9}\n",
    "            ],\n",
    "            'linear_trend': [{'attr': 'slope'}],\n",
    "            'approximate_entropy': [{'m': 2, 'r': 0.25}],\n",
    "            'ratio_beyond_r_sigma': [{'r': 2}],\n",
    "            'autocorrelation': [{'lag': 1}],\n",
    "            'fft_aggregated': [{'aggtype': 'centroid'}, {'aggtype': 'variance'}],\n",
    "            'longest_strike_above_mean': None,\n",
    "            'longest_strike_below_mean': None,\n",
    "            'count_above_mean': None,\n",
    "        }\n",
    "        features = extract_features(\n",
    "            timeseries_container=df,\n",
    "            column_id='client_id',\n",
    "            column_sort=date_col,\n",
    "            column_value=val_col,\n",
    "            default_fc_parameters=fc_parameters,\n",
    "            n_jobs=14,\n",
    "        )\n",
    "        features = features.reset_index(names='client_id')\n",
    "        all_features.append(features)\n",
    "\n",
    "final_features = feature_matrix_enc\n",
    "for features in all_features:\n",
    "    final_features = final_features.merge(features, on='client_id', how='left')\n",
    "\n",
    "display(final_features.info(verbose=True, show_counts=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6cfb68c13793a6b8",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "7f437df9b0a9ea27",
   "metadata": {},
   "source": [
    "df = final_features\n",
    "df = df.reset_index()\n",
    "# df = df.drop(columns=['client_id'])\n",
    "df = df.dropna(subset=[\n",
    "    # Transactions\n",
    "    'NUM_UNIQUE(transactions.tran_date_str)', 'MEAN(transactions.float_c16 WHERE int_c19 = -1)', 'MEAN(transactions.float_c16 WHERE int_c19 = 1)',\n",
    "\n",
    "    # Activities\n",
    "    'NUM_UNIQUE(activities.activity_date_str)', 'STD(activities.float_c11)',\n",
    "\n",
    "    # Communications\n",
    "    'NUM_UNIQUE(comms.contact_date_str)',\n",
    "])\n",
    "\n",
    "# Convert dates to days from initial point\n",
    "for date_col in df.select_dtypes(include=['datetime64[ns]']).columns:\n",
    "    df[date_col + '_days'] = (df[date_col] - pd.to_datetime(MIN_DATE_STR)).dt.days\n",
    "    df = df.drop(columns=[date_col])\n",
    "\n",
    "# Encode cyclical features (e.g. day of week, month)\n",
    "time_cols = ['DAY(communication_month)', 'MONTH(communication_month)', 'WEEKDAY(communication_month)']\n",
    "df = df.astype({col: 'int8' for col in time_cols})\n",
    "cyclical = CyclicalFeatures(variables=time_cols, drop_original=True)\n",
    "df = cyclical.fit_transform(df)\n",
    "\n",
    "# Fill  missing data\n",
    "cols_to_fill_with_mean = [\n",
    "    c for c in df.columns\n",
    "    if (' WHERE ' in c and c.startswith('MEAN(')\n",
    "        or c.startswith('SKEW(')\n",
    "        or c.endswith('__skewness')\n",
    "        or c.endswith('__kurtosis')\n",
    "        or '__autocorrelation' in c\n",
    "        or '__fft_aggregated__aggtype' in c)\n",
    "]\n",
    "ami = AddMissingIndicator(variables=cols_to_fill_with_mean)\n",
    "df = ami.fit_transform(df)\n",
    "mmi = MeanMedianImputer(imputation_method='mean', variables=cols_to_fill_with_mean)\n",
    "df = mmi.fit_transform(df)\n",
    "\n",
    "# Convert boolean values to 0 and 1\n",
    "df = df.astype({col: 'int8' for col in df.select_dtypes(include=['bool']).columns})\n",
    "df = df.astype({col: 'Int8' for col in df.select_dtypes(include=['boolean']).columns})\n",
    "\n",
    "df.to_csv('../data/features/features_auto_v5_single.csv', index=False)\n",
    "display(df.info(verbose=True, show_counts=True))\n",
    "display(df.describe())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26ae60bf44a08376",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
